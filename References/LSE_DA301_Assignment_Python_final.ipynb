{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### LSE Data Analytics Online Career Accelerator \n",
    "\n",
    "# DA301:  Advanced Analytics for Organisational Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import string\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from helper_functions import *\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score\n",
    "from aquarel import load_theme\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Import specific functions from libraries\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "# Ignore warnings to keep the output clean\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# Get the IPython instance to interact with the IPython environment\n",
    "ipython = get_ipython()\n",
    "\n",
    "# Define a custom cell magic command to skip data cleaning steps in subsequent runs\n",
    "@register_cell_magic\n",
    "def skip_if(line, cell):\n",
    "    # Evaluate the condition provided in the line argument\n",
    "    if eval(line):\n",
    "        return  # Skip the cell if the condition is True\n",
    "    # Otherwise, execute the cell\n",
    "    ipython.run_cell(cell)\n",
    "\n",
    "# If this variable is set to True. Skips cleaning during reruns of code if not required\n",
    "no_cleaning = False\n",
    "no_regression = False\n",
    "no_decision_tree = False\n",
    "no_k_means = False\n",
    "no_NLP = False\n",
    "no_sentiment_calculation = False  # set to False for recalculation\n",
    "\n",
    "# Set the display options to use the full width of the screen\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "theme = load_theme(\"scientific\")\n",
    "theme.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_cleaning\n",
    "# Load the CSV file(s) as reviews.\n",
    "# If pickle file exists, read it; otherwise, read the CSV and convert to pickle\n",
    "# This ensures faster loading from the second run and avoids reading the CSV file when resetting the kernel\n",
    "if not os.path.exists(\"turtle_reviews.pickle\"):\n",
    "    # Read the CSV file and convert it to a pickle file\n",
    "    reviews = pd.read_csv('turtle_reviews.csv')\n",
    "    reviews.to_pickle('turtle_reviews.pickle')\n",
    "    # Read the newly created pickle file\n",
    "    reviews = pd.read_pickle('turtle_reviews.pickle')\n",
    "else:\n",
    "    # Read the existing pickle file\n",
    "    reviews = pd.read_pickle('turtle_reviews.pickle')\n",
    "\n",
    "# # View the DataFrame.\n",
    "# print(\"Head \\n\", reviews.head())\n",
    "# print(\"Types\\n\", reviews.dtypes)\n",
    "# print(\"Shape\\n\", reviews.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_cleaning\n",
    "\n",
    "# Determine whether there are missing values in the DataFrame\n",
    "reviews_na = reviews[reviews.isna().any(axis=1)]\n",
    "\n",
    "# Drop rows with missing values from the DataFrame\n",
    "reviews.drop(reviews_na.index, axis=0, inplace=True)\n",
    "\n",
    "# Identify duplicate rows in the DataFrame\n",
    "reviews_duplicates = reviews[reviews.duplicated(keep=False)]\n",
    "\n",
    "# Drop duplicate rows from the DataFrame, keeping the first occurrence\n",
    "reviews.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "# Reset the index of the DataFrame after dropping rows\n",
    "reviews.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_cleaning\n",
    "reviews['gender']= reviews['gender'].astype('category')\n",
    "reviews['product']= reviews['product'].astype('category')\n",
    "reviews['education']= reviews['education'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_cleaning\n",
    "# Basic descriptive statistics.\n",
    "reviews.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_cleaning\n",
    "# Drop unnecessary columns.\n",
    "reviews = reviews[['gender', 'age', 'remuneration (k£)', 'spending_score (1-100)',\n",
    "         'loyalty_points', 'education', 'product',\n",
    "         'review','summary']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_cleaning\n",
    "# Rename the column headers.\n",
    "reviews = reviews.rename(columns = {'remuneration (k£)':'remuneration', 'spending_score (1-100)': 'spending_score'})\n",
    "reviews['remuneration'] = reviews['remuneration'].apply(lambda x: x*1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_cleaning\n",
    "# Create a CSV file as output.\n",
    "reviews.to_csv('reviews_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import new CSV file with Pandas.\n",
    "reviews_cleaned = pd.read_csv('reviews_cleaned.csv')\n",
    "print(\"Types\\n\", reviews_cleaned.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "reviews_cleaned = pd.read_csv('reviews_cleaned.csv')\n",
    "\n",
    "# Split the dataset into training and testing sets with 80% of the data in the training set\n",
    "reviews_train, reviews_test = train_test_split(reviews_cleaned, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"Training set shape:\", reviews_train.shape)\n",
    "print(\"Testing set shape:\", reviews_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_regression\n",
    "# Create model and print summary of metrics.\n",
    "loyalty_models = get_regression_results_with_plot(\n",
    "    indep_vars =['spending_score', 'remuneration', 'age'],\n",
    "    dep_var ='loyalty_points',\n",
    "    data=reviews_cleaned,\n",
    "    outliers_removed = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_regression\n",
    "check_regression_assumptions(model_input= loyalty_models['spending_score'], X = reviews_cleaned[['spending_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_regression\n",
    "check_regression_assumptions(model_input= loyalty_models['remuneration'], X = reviews_cleaned[['remuneration']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_regression\n",
    "# Create model and print summary of metrics.\n",
    "\n",
    "reviews_cleaned['log_loyalty_points'] =np.log1p(reviews_cleaned['loyalty_points'])\n",
    "reviews_cleaned['log_spending_score'] =np.log1p(reviews_cleaned['spending_score'])\n",
    "reviews_cleaned['log_remuneration'] =np.log1p(reviews_cleaned['remuneration'])\n",
    "\n",
    "loyalty_models_weighted = get_regression_results_with_plot(\n",
    "    indep_vars =['log_spending_score', 'log_remuneration'],\n",
    "    dep_var ='log_loyalty_points',\n",
    "    data=reviews_cleaned,\n",
    "    outliers_removed = False,\n",
    "    weighted= False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_regression\n",
    "check_regression_assumptions(model_input= loyalty_models_weighted['log_spending_score'], X = reviews_cleaned[['log_spending_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_regression\n",
    "check_regression_assumptions(model_input= loyalty_models_weighted['log_remuneration'], X = reviews_cleaned[['log_remuneration']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the estimated parameters.\n",
    "# # Print R-squared value of the train data.\n",
    "# print(\"R-squared value: \", loyalty_models['spending_score'].rsquared)\n",
    "#\n",
    "# # Print the intercept value.\n",
    "# print(\"Intercept value: \", loyalty_models['spending_score'].params[0])\n",
    "#\n",
    "# # Print the coefficient value.\n",
    "# print(\"Coefficient value: \", loyalty_models['spending_score'].params[1])\n",
    "#\n",
    "# # Extract the standard errors.\n",
    "# print(\"Standard Errors: \", loyalty_models['spending_score'].bse)\n",
    "#\n",
    "# # Extract the predicted values.\n",
    "# print(\"Predicted Values: \", loyalty_models['spending_score'].predict(reviews_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_regression\n",
    "loyalty_models['spending_score'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loyalty_models['remuneration'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loyalty_models['age'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_regression\n",
    "loyalty_multi_var_model = multivariate_regression_3d_plot(\n",
    "    indep_vars =['spending_score', 'remuneration'],\n",
    "    dep_var ='loyalty_points',\n",
    "    data=reviews_cleaned,\n",
    "    show_plot = True,\n",
    "    outliers_removed = False,\n",
    "    elevation=10,\n",
    "    azimuth=-50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_regression\n",
    "check_regression_assumptions(model_input= loyalty_multi_var_model, X = reviews_cleaned[['spending_score', 'remuneration']], multi= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_decision_tree\n",
    "# Convert categorical variables to dummy variables\n",
    "reviews_dt = reviews_cleaned.drop(columns=['review', 'summary', 'product', 'log_remuneration', 'log_loyalty_points', 'log_spending_score', 'log_remuneration'])\n",
    "metrics = evaluate_decision_tree_regressor(reviews_dt, use_columns=['age', 'remuneration', 'spending_score', 'gender', 'education'], depth=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_decision_tree\n",
    "\n",
    "progress_check = []\n",
    "\n",
    "for iter_tree in range(1, 15):\n",
    "    metrics = evaluate_decision_tree_regressor(\n",
    "        reviews_dt,\n",
    "        use_columns=['age', 'remuneration', 'spending_score', 'gender', 'education'],\n",
    "        depth=iter_tree,\n",
    "        showplot=False,\n",
    "        showstats=False\n",
    "    )\n",
    "    progress_check.append([iter_tree, metrics['mean_squared_error'], metrics['r2_score']])\n",
    "\n",
    "# Convert the progress_check list to a DataFrame\n",
    "df = pd.DataFrame(progress_check, columns=['Depth', 'Mean Squared Error', 'R-squared'])\n",
    "\n",
    "# Set the 'Depth' column as the index\n",
    "df.set_index('Depth', inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Extracting data for plotting changes\n",
    "depths = [item[0] for item in progress_check[1:]]  # Start from the second element\n",
    "mse_changes = [abs(((progress_check[i][1] - progress_check[i-1][1]) / progress_check[i-1][1])) * 100 for i in range(1, len(progress_check))]\n",
    "r2_changes = [((progress_check[i][2] - progress_check[i-1][2]) / progress_check[i-1][2]) * 100 for i in range(1, len(progress_check))]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot MSE Changes\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(depths, mse_changes, marker='o', color='blue')\n",
    "plt.title('Percentage Change in MSE vs. Tree Depth')\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('Percentage Change in MSE')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add data labels for MSE changes\n",
    "for i, change in enumerate(mse_changes):\n",
    "    plt.text(depths[i], change, f'{change:.2f}%', fontsize=9, ha='center', va='bottom')\n",
    "\n",
    "# Plot R2 Changes\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(depths, r2_changes, marker='o', color='orange')\n",
    "plt.title('Percentage Change in R-squared vs. Tree Depth')\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('Percentage Change in R-squared')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add data labels for R2 changes\n",
    "for i, change in enumerate(r2_changes):\n",
    "    plt.text(depths[i], change, f'{change:.2f}%', fontsize=9, ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_decision_tree\n",
    "\n",
    "metrics = evaluate_random_forest_regressor(\n",
    "    reviews_dt,\n",
    "    use_columns=['age', 'remuneration', 'spending_score', 'gender', 'education'],\n",
    "    showstats=True,\n",
    "    max_depth=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_decision_tree\n",
    "\n",
    "data = reviews_dt\n",
    "\n",
    "# Define features and target variable\n",
    "X = data[['age', 'remuneration', 'spending_score', 'gender', 'education']].copy()\n",
    "y = data['loyalty_points'].copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "X = pd.get_dummies(X, columns=categorical_columns)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%skip_if no_decision_tree\n",
    "\n",
    "# Define the parameter distributions to sample from\n",
    "param_dist = {\n",
    "    'max_depth': randint(1, 7),  # randint from scipy.stats\n",
    "    'min_samples_split': randint(30, 1000),\n",
    "    'min_samples_leaf': randint(30, 100),\n",
    "    'ccp_alpha': uniform(0.01, 0.1),          # float between 0.01 and 0.11 (0.01 + 0.1)\n",
    "    'min_impurity_decrease': uniform(0.1, 0.2)\n",
    "}\n",
    "\n",
    "# Create a Decision Tree Regressor\n",
    "dtree_reg = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Use RandomizedSearchCV to search for the best parameters\n",
    "random_search = RandomizedSearchCV(\n",
    "    dtree_reg,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "results_random_search = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_dtree_reg = random_search.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best estimator\n",
    "y_pred = best_dtree_reg.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error and Root Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "# Retrieve the best parameters and best score from the grid search\n",
    "best_params = random_search.best_params_\n",
    "best_score_grid = random_search.best_score_\n",
    "\n",
    "# Retrieve the best parameters and best score\n",
    "best_params_random = random_search.best_params_\n",
    "best_score_random = random_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params_random}\")\n",
    "print(f\"Best Score (Random Search): {best_score_random}\")\n",
    "print(f\"Test RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic stats of y_test\n",
    "y_test_mean = np.mean(y_test)\n",
    "y_test_min = np.min(y_test)\n",
    "y_test_max = np.max(y_test)\n",
    "y_test_std = np.std(y_test)\n",
    "\n",
    "# Calculate Normalized RMSE (by range and mean)\n",
    "nrmse_range = rmse / (y_test_max - y_test_min)\n",
    "nrmse_mean = rmse / y_test_mean\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params_random}\")\n",
    "print(f\"Best Score (Random Search): {best_score_random}\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(\"\\n--- Target Variable Statistics (Test Set) ---\")\n",
    "print(f\"Mean: {y_test_mean:.4f}\")\n",
    "print(f\"Min: {y_test_min:.4f}\")\n",
    "print(f\"Max: {y_test_max:.4f}\")\n",
    "print(f\"Std Dev: {y_test_std:.4f}\")\n",
    "\n",
    "print(\"\\n--- Normalized RMSE ---\")\n",
    "print(f\"NRMSE (range): {nrmse_range:.4f}\")\n",
    "print(f\"NRMSE (mean): {nrmse_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals on test set\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot: Predicted vs Residuals\n",
    "axes[0].scatter(y_pred, residuals, alpha=0.6)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0].set_xlabel('Predicted values')\n",
    "axes[0].set_ylabel('Residuals (Actual - Predicted)')\n",
    "axes[0].set_title('Residual Plot')\n",
    "\n",
    "# Histogram of residuals to check their distribution\n",
    "sns.histplot(residuals, kde=True, ax=axes[1])\n",
    "axes[1].set_title('Residuals Distribution')\n",
    "axes[1].set_xlabel('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_random = {\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 82,\n",
    "    'min_samples_leaf': 37,\n",
    "    'ccp_alpha': 0.01388347344294232,\n",
    "    'min_impurity_decrease': 0.2074164854393311\n",
    "}\n",
    "# Train the model\n",
    "tree_model_random = DecisionTreeRegressor(**best_params_random)\n",
    "\n",
    "\n",
    "# Try different seeds\n",
    "evaluate_model_with_seed(tree_model_random, X, y, seed=123)\n",
    "evaluate_model_with_seed(tree_model_random, X, y, seed=2024)\n",
    "evaluate_model_with_seed(tree_model_random, X, y, seed=99)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model_random.fit(X, y)\n",
    "\n",
    "plt.figure(figsize=(40, 20))  # Large figure size for high resolution\n",
    "plot_tree(tree_model_random,\n",
    "          filled=True,\n",
    "          feature_names=X.columns,\n",
    "          fontsize=8)\n",
    "\n",
    "# Save the plot as a high-quality PNG file\n",
    "file_path = 'decision_tree_random_optimization.png'\n",
    "plt.savefig(file_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.close()\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_decision_tree\n",
    "\n",
    "# Define the function to optimize using cross-validation\n",
    "def dtree_cv(max_depth, min_samples_split, min_samples_leaf, ccp_alpha,min_impurity_decrease):\n",
    "    # Define the model with the parameters to be optimized\n",
    "    estimator = DecisionTreeRegressor(\n",
    "        max_depth=int(max_depth),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        min_samples_leaf=int(min_samples_leaf),\n",
    "        random_state=2,\n",
    "        ccp_alpha = float(ccp_alpha),\n",
    "        min_impurity_decrease = float(min_impurity_decrease)\n",
    "    )\n",
    "    cval = cross_val_score(estimator, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "    return cval.mean()  # The optimizer tries to maximize the function\n",
    "\n",
    "# Define the parameter bounds\n",
    "param_bounds = {\n",
    "    'max_depth': (1, 7),\n",
    "    'min_samples_split': (30, 100),\n",
    "    'min_samples_leaf': (30, 100),\n",
    "    'ccp_alpha': (0.01, 0.1),\n",
    "    'min_impurity_decrease': (0.1, 0.3)\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=dtree_cv,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(n_iter=25, init_points=5)  # Bayesian optimization\n",
    "\n",
    "# Extract the best parameters\n",
    "best_params_bayes = optimizer.max['params']\n",
    "best_params_bayes['max_depth'] = int(best_params_bayes['max_depth'])\n",
    "best_params_bayes['min_samples_split'] = int(best_params_bayes['min_samples_split'])\n",
    "best_params_bayes['min_samples_leaf'] = int(best_params_bayes['min_samples_leaf'])\n",
    "\n",
    "# Fit the best model on the training data\n",
    "best_dtree_reg = DecisionTreeRegressor(**best_params_bayes, random_state=42)\n",
    "best_dtree_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred = best_dtree_reg.predict(X_test)\n",
    "\n",
    "# Calculate Test RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "best_score_bayes = optimizer.max['target']\n",
    "\n",
    "print(f\"Best Parameters (Bayesian Optimization): {best_params_bayes}\")\n",
    "print(f\"Best Score (Bayesian Optimization): {best_score_bayes}\")\n",
    "print(f\"Test RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic stats of y_test\n",
    "y_test_mean = np.mean(y_test)\n",
    "y_test_min = np.min(y_test)\n",
    "y_test_max = np.max(y_test)\n",
    "y_test_std = np.std(y_test)\n",
    "\n",
    "# Calculate Normalized RMSE (by range and mean)\n",
    "nrmse_range = rmse / (y_test_max - y_test_min)\n",
    "nrmse_mean = rmse / y_test_mean\n",
    "\n",
    "print(f\"Best Parameters (Bayesian Optimization): {best_params_bayes}\")\n",
    "print(f\"Best Score (Bayesian Optimization): {best_score_bayes}\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(\"\\n--- Target Variable Statistics (Test Set) ---\")\n",
    "print(f\"Mean: {y_test_mean:.4f}\")\n",
    "print(f\"Min: {y_test_min:.4f}\")\n",
    "print(f\"Max: {y_test_max:.4f}\")\n",
    "print(f\"Std Dev: {y_test_std:.4f}\")\n",
    "\n",
    "print(\"\\n--- Normalized RMSE ---\")\n",
    "print(f\"NRMSE (range): {nrmse_range:.4f}\")\n",
    "print(f\"NRMSE (mean): {nrmse_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals on test set\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot: Predicted vs Residuals\n",
    "axes[0].scatter(y_pred, residuals, alpha=0.6)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0].set_xlabel('Predicted values')\n",
    "axes[0].set_ylabel('Residuals (Actual - Predicted)')\n",
    "axes[0].set_title('Residual Plot')\n",
    "\n",
    "# Histogram of residuals to check their distribution\n",
    "sns.histplot(residuals, kde=True, ax=axes[1])\n",
    "axes[1].set_title('Residuals Distribution')\n",
    "axes[1].set_xlabel('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_bayesian = {\n",
    "    'max_depth': 7,\n",
    "    'min_samples_split': 66,\n",
    "    'min_samples_leaf': 31,\n",
    "    'ccp_alpha': 0.01,\n",
    "    'min_impurity_decrease': 0.3\n",
    "}\n",
    "\n",
    "tree_model_bayesian = DecisionTreeRegressor(**best_params_bayesian)\n",
    "\n",
    "# Try different seeds\n",
    "evaluate_model_with_seed(tree_model_bayesian, X, y, seed=123)\n",
    "evaluate_model_with_seed(tree_model_bayesian, X, y, seed=2024)\n",
    "evaluate_model_with_seed(tree_model_bayesian, X, y, seed=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model_bayesian.fit(X, y)\n",
    "\n",
    "# Attempt to plot and save the decision tree again\n",
    "plt.figure(figsize=(40, 20))  # Large figure size for high resolution\n",
    "plot_tree(tree_model_bayesian,\n",
    "          filled=True,\n",
    "          feature_names=X.columns,\n",
    "          fontsize=8)\n",
    "\n",
    "# Save the plot as a high-quality PNG file\n",
    "file_path = 'decision_tree_bayesian_optimization.png'\n",
    "plt.savefig(file_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.close()\n",
    "file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_k_means\n",
    "\n",
    "# Select only the features to use\n",
    "reviews_k_map = reviews_cleaned[['remuneration', 'spending_score']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_k_means\n",
    "\n",
    "# Create a scatterplot with Seaborn.\n",
    "# Create a scatter plot of remuneration versus spending_score\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=reviews_k_map, x='remuneration', y='spending_score')\n",
    "plt.title('Scatter Plot of Remuneration vs Spending Score')\n",
    "plt.xlabel('Remuneration')\n",
    "plt.ylabel('Spending Score')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_k_means\n",
    "#Create a pair plot with Seaborn\n",
    "\n",
    "sns.pairplot(reviews_k_map, height=3.5, aspect=1.2)\n",
    "plt.suptitle('Pair Plot of Remuneration and Spending Score', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_k_means\n",
    "\n",
    "# Run KMeans clustering\n",
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "reviews_k_map['cluster'] = kmeans.fit_predict(reviews_k_map[['remuneration', 'spending_score']])\n",
    "\n",
    "# Plot the clustering result\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=reviews_k_map,\n",
    "    x='remuneration',\n",
    "    y='spending_score',\n",
    "    hue='cluster',\n",
    "    palette='viridis',\n",
    "    s=50\n",
    ")\n",
    "\n",
    "# Plot cluster centroids\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, marker='X', label='Centroids')\n",
    "\n",
    "# Plot aesthetics\n",
    "plt.title('K-means Clustering (k=8)')\n",
    "plt.xlabel('Remuneration')\n",
    "plt.ylabel('Spending Score')\n",
    "plt.legend(title='Cluster', loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_k_means\n",
    "\n",
    "# Standardize the data\n",
    "features = reviews_cleaned[['remuneration', 'spending_score']].copy()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Fit KMeans\n",
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "centers_original = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "\n",
    "# Add results back for plotting\n",
    "features['cluster'] = clusters\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Plot in scaled feature space\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    x='remuneration',\n",
    "    y='spending_score',\n",
    "    data = features,\n",
    "    hue=clusters,\n",
    "    palette='viridis',\n",
    "    s=50\n",
    ")\n",
    "plt.scatter(centers_original[:, 0], centers_original[:, 1], c='red', s=200, marker='X', label='Centroids')\n",
    "plt.title('K-means Clustering (k=8) on Standardized Features')\n",
    "plt.xlabel('Standardized Remuneration')\n",
    "plt.ylabel('Standardized Spending Score')\n",
    "plt.legend(title='Cluster', loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_k_means\n",
    "\n",
    "# Calculate inertia for different values of k\n",
    "inertia = []\n",
    "K = range(1, 10)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Calculate the raw change in inertia\n",
    "inertia_change_raw = np.diff(inertia)\n",
    "\n",
    "# Plot the Elbow Method graph and the raw change in inertia\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12))\n",
    "# Elbow Method plot\n",
    "ax1.plot(K, inertia, 'bo-')\n",
    "ax1.set_xlabel('Number of Clusters')\n",
    "ax1.set_ylabel('Inertia')\n",
    "ax1.set_title('Elbow Method For Optimal Number of Clusters')\n",
    "ax1.set_xticks(K)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Raw change in inertia plot\n",
    "K_change = range(2, 10)  # Since we start calculating change from the second value\n",
    "ax2.plot(K_change, inertia_change_raw, 'ro-')\n",
    "\n",
    "# Label each point with its value\n",
    "for i, txt in enumerate(inertia_change_raw):\n",
    "    ax2.annotate(f\"{txt:.2f}\", (K_change[i], inertia_change_raw[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "ax2.set_xlabel('Number of Clusters')\n",
    "ax2.set_ylabel('Raw Change in Inertia')\n",
    "ax2.set_title('Raw Change in Inertia')\n",
    "ax2.set_xticks(K_change)\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_k_means\n",
    "\n",
    "# Determine the number of clusters: Silhouette method.\n",
    "K = range(2, 10)  # We start from 2 because silhouette score is not defined for a single cluster\n",
    "silhouette_scores = []\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "    silhouette_avg = silhouette_score(X_scaled, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot the Silhouette Method graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K, silhouette_scores, 'bo-')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Method For Optimal Number of Clusters')\n",
    "plt.xticks(K)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_k_means\n",
    "\n",
    "# Create a 3x2 grid of subplots\n",
    "fig, axs = plt.subplots(3, 2, figsize=(18, 16))\n",
    "\n",
    "# Flatten the array of axes for easy iteration\n",
    "axs = axs.ravel()\n",
    "\n",
    "# Plot for different values of k\n",
    "for k, ax in zip(range(3, 9), axs):\n",
    "    # Fit KMeans\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    centers_original = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "\n",
    "    # Add results back for plotting\n",
    "    features['cluster'] = clusters\n",
    "\n",
    "    # Count the number of points in each cluster\n",
    "    cluster_counts = features['cluster'].value_counts().sort_index()\n",
    "\n",
    "    # Define a color palette with enough distinct colors\n",
    "    palette = sns.color_palette(\"viridis\", k)\n",
    "\n",
    "    # Plot in scaled feature space\n",
    "    sns.scatterplot(\n",
    "        x='remuneration',\n",
    "        y='spending_score',\n",
    "        data=features,\n",
    "        hue='cluster',\n",
    "        palette=palette,\n",
    "        s=50,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Plot centroids without labels\n",
    "    ax.scatter(centers_original[:, 0], centers_original[:, 1], c='red', s=200, marker='X')\n",
    "\n",
    "    # Custom legend labels with cluster number and counts\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    custom_labels = [f\"Cluster {i}: {count} points\" for i, count in cluster_counts.items()]\n",
    "    ax.legend(handles=handles[:len(custom_labels)], labels=custom_labels, title='Clusters',\n",
    "              loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    ax.set_title(f'K-means Clustering (k={k})')\n",
    "    ax.set_xlabel('Remuneration')\n",
    "    ax.set_ylabel('Spending Score')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "# Fill empty entries in the 'review' and 'summary' columns with an empty string\n",
    "reviews_nlp = reviews_cleaned[['review', 'summary']].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "# Convert text to lower case\n",
    "reviews_nlp['review'] = reviews_nlp['review'].str.lower()\n",
    "reviews_nlp['summary'] = reviews_nlp['summary'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "reviews_nlp_copy = reviews_nlp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "# Function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Remove punctuation\n",
    "reviews_nlp_copy['review'] = reviews_nlp_copy['review'].apply(remove_punctuation)\n",
    "reviews_nlp_copy['summary'] = reviews_nlp_copy['summary'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "# Tokenize the text\n",
    "reviews_nlp_copy['review_tokens'] = reviews_nlp_copy['review'].apply(word_tokenize)\n",
    "reviews_nlp_copy['summary_tokens'] = reviews_nlp_copy['summary'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "# Function to generate word cloud\n",
    "def generate_wordcloud(text):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(text))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Generate word clouds\n",
    "generate_wordcloud(reviews_nlp_copy['review_tokens'].sum())\n",
    "generate_wordcloud(reviews_nlp_copy['summary_tokens'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "# Frequency distribution for reviews\n",
    "freq_dist_review = FreqDist(reviews_nlp_copy['review_tokens'].sum())\n",
    "freq_dist_review.plot(30, cumulative=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "freq_dist_summary = FreqDist(reviews_nlp_copy['summary_tokens'].sum())\n",
    "freq_dist_review.plot(30, cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "# Remove alphanumeric characters from tokens\n",
    "filtered_review_tokens = reviews_nlp_copy['review_tokens'].apply(lambda x: [word for word in x if word.isalpha()])\n",
    "filtered_summary_tokens = reviews_nlp_copy['summary_tokens'].apply(lambda x: [word for word in x if word.isalpha()])\n",
    "\n",
    "\n",
    "reviews_nlp_copy['review_tokens'] = filtered_review_tokens\n",
    "reviews_nlp_copy['summary_tokens'] = filtered_summary_tokens\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_review_tokens = reviews_nlp_copy['review_tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "filtered_summary_tokens = reviews_nlp_copy['summary_tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "reviews_nlp_copy['review_tokens'] = filtered_review_tokens\n",
    "reviews_nlp_copy['summary_tokens'] = filtered_summary_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "# Generate word clouds without stopwords\n",
    "generate_wordcloud(filtered_review_tokens.sum())\n",
    "generate_wordcloud(filtered_summary_tokens.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "# Flatten the token lists to find the most common words\n",
    "flat_review_tokens = [word for sublist in reviews_nlp_copy['review_tokens'] for word in sublist]\n",
    "flat_summary_tokens = [word for sublist in reviews_nlp_copy['summary_tokens'] for word in sublist]\n",
    "\n",
    "# Most common words\n",
    "freq_dist_review = FreqDist(flat_review_tokens)\n",
    "freq_dist_summary = FreqDist(flat_summary_tokens)\n",
    "\n",
    "most_common_review_words = freq_dist_review.most_common(15)\n",
    "most_common_summary_words = freq_dist_summary.most_common(15)\n",
    "\n",
    "print(\"Most common words in reviews:\", most_common_review_words)\n",
    "print(\"Most common words in summaries:\", most_common_summary_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "csv_path = \"reviews_nlp_with_sentiment.csv\"\n",
    "\n",
    "if no_sentiment_calculation and os.path.exists(csv_path):\n",
    "    print(\"Loading precomputed sentiment data...\")\n",
    "    reviews_nlp = pd.read_csv(csv_path)\n",
    "else:\n",
    "    print(\"Computing sentiment features...\")\n",
    "\n",
    "    # === TextBlob ===\n",
    "    reviews_nlp['textblob_review_polarity'] = reviews_nlp['review'].apply(textblob_polarity)\n",
    "    reviews_nlp['textblob_summary_polarity'] = reviews_nlp['summary'].apply(textblob_polarity)\n",
    "\n",
    "    # === VADER ===\n",
    "    reviews_nlp['vader_review_polarity'] = reviews_nlp['review'].apply(vader_polarity)\n",
    "    reviews_nlp['vader_summary_polarity'] = reviews_nlp['summary'].apply(vader_polarity)\n",
    "\n",
    "    # === Afinn (raw and scaled) ===\n",
    "    reviews_nlp['afinn_review_polarity'] = reviews_nlp['review'].apply(afinn_polarity)\n",
    "    reviews_nlp['afinn_review_polarity'] = reviews_nlp.apply(\n",
    "        lambda row: scale_afinn_by_length(row['review'], row['afinn_review_polarity']),\n",
    "        axis=1\n",
    "    )\n",
    "    reviews_nlp['afinn_summary_polarity'] = reviews_nlp['summary'].apply(afinn_polarity)\n",
    "    reviews_nlp['afinn_summary_polarity'] = reviews_nlp.apply(\n",
    "        lambda row: scale_afinn_by_length(row['summary'], row['afinn_summary_polarity']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # === RoBERTa (batch) ===\n",
    "    reviews_nlp['roberta_review_polarity'] = roberta_scaled_scores(reviews_nlp['review'].tolist())\n",
    "    reviews_nlp['roberta_summary_polarity'] = roberta_scaled_scores(reviews_nlp['summary'].tolist())\n",
    "\n",
    "    # === BERT (batch) ===\n",
    "    reviews_nlp['bert_review_polarity'] = bert_scaled_scores(reviews_nlp['review'].tolist())\n",
    "    reviews_nlp['bert_summary_polarity'] = bert_scaled_scores(reviews_nlp['summary'].tolist())\n",
    "\n",
    "    # Save for reuse\n",
    "    reviews_nlp.to_csv(csv_path, index=False)\n",
    "    print(f\"Sentiment scores saved to {csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "# Create a figure with 2 rows and 3 columns to fit all five sentiment methods\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Flatten axes array for easy indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot TextBlob Review Polarity\n",
    "sns.histplot(reviews_nlp['textblob_review_polarity'], bins=25, kde=True, stat=\"count\", ax=axes[0], color='blue')\n",
    "axes[0].set_title('TextBlob Review Polarity')\n",
    "\n",
    "# Plot VADER Review Polarity\n",
    "sns.histplot(reviews_nlp['vader_review_polarity'], bins=25, kde=True, stat=\"count\", ax=axes[1], color='green')\n",
    "axes[1].set_title('VADER Review Polarity')\n",
    "\n",
    "# Plot Afinn Review Polarity\n",
    "sns.histplot(reviews_nlp['afinn_review_polarity'], bins=25, kde=True, stat=\"count\", ax=axes[2], color='red')\n",
    "axes[2].set_title('Afinn Review Polarity')\n",
    "\n",
    "# Plot RoBERTa Review Polarity\n",
    "sns.histplot(reviews_nlp['roberta_review_polarity'], bins=25, kde=True, stat=\"count\", ax=axes[3], color='purple')\n",
    "axes[3].set_title('RoBERTa Review Polarity')\n",
    "\n",
    "# Plot BERT Review Polarity\n",
    "sns.histplot(reviews_nlp['bert_review_polarity'], bins=25, kde=True, stat=\"count\", ax=axes[4], color='orange')\n",
    "axes[4].set_title('BERT Review Polarity')\n",
    "\n",
    "# Hide the 6th subplot (empty)\n",
    "axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "# Create a figure with 2 rows and 3 columns to fit all five sentiment methods\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Flatten axes array for easy indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot TextBlob Review Polarity\n",
    "sns.histplot(reviews_nlp['textblob_summary_polarity'], bins=25, kde=True, stat=\"count\", ax=axes[0], color='blue')\n",
    "axes[0].set_title('TextBlob Summary Polarity')\n",
    "\n",
    "# Plot VADER Review Polarity\n",
    "sns.histplot(reviews_nlp['vader_summary_polarity'], bins=25, kde=True, stat=\"count\", ax=axes[1], color='green')\n",
    "axes[1].set_title('VADER Summary Polarity')\n",
    "\n",
    "# Plot Afinn Review Polarity\n",
    "sns.histplot(reviews_nlp['afinn_summary_polarity'], bins=25, kde=True, stat=\"count\", ax=axes[2], color='red')\n",
    "axes[2].set_title('Afinn Summary Polarity')\n",
    "\n",
    "# Plot RoBERTa Review Polarity\n",
    "sns.histplot(reviews_nlp['roberta_summary_polarity'], bins=25, kde=True, stat=\"count\", ax=axes[3], color='purple')\n",
    "axes[3].set_title('RoBERTa Summary Polarity')\n",
    "\n",
    "# Plot BERT Review Polarity\n",
    "sns.histplot(reviews_nlp['bert_summary_polarity'], bins=25, kde=True, stat=\"count\", ax=axes[4], color='orange')\n",
    "axes[4].set_title('BERT Summary Polarity')\n",
    "\n",
    "# Hide the 6th subplot (empty)\n",
    "axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "review_fields = [\n",
    "    'textblob_review_polarity',\n",
    "    'vader_review_polarity',\n",
    "    'afinn_review_polarity',\n",
    "    'roberta_review_polarity',\n",
    "    'bert_review_polarity'\n",
    "]\n",
    "\n",
    "reviews_nlp['combined_review_polarity'] = reviews_nlp.apply(\n",
    "    lambda row: combined_sentiment_zero_aware(row, review_fields),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "summary_fields = [\n",
    "    'textblob_summary_polarity',\n",
    "    'vader_summary_polarity',\n",
    "    'afinn_summary_polarity',\n",
    "    'roberta_summary_polarity',\n",
    "    'bert_summary_polarity'\n",
    "]\n",
    "\n",
    "reviews_nlp['combined_summary_polarity'] = reviews_nlp.apply(\n",
    "    lambda row: combined_sentiment_zero_aware(row, summary_fields),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_nlp.loc[reviews_nlp['combined_summary_polarity'] == 0.9928, 'combined_summary_polarity'] = \\\n",
    "    reviews_nlp['combined_review_polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot combined_review_polarity\n",
    "sns.histplot(reviews_nlp['combined_review_polarity'], bins=30, kde=True, ax=axes[0], color='#89b4fa')\n",
    "axes[0].set_title(\"Combined Review Polarity\")\n",
    "axes[0].set_xlabel(\"Polarity Score\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "# Plot combined_summary_polarity\n",
    "sns.histplot(reviews_nlp['combined_summary_polarity'], bins=30, kde=True, ax=axes[1], color='#f38ba8')\n",
    "axes[1].set_title(\"Combined Summary Polarity\")\n",
    "axes[1].set_xlabel(\"Polarity Score\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "\n",
    "# Tidy layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "print(\"Top 20 Positive Reviews by Combined Review Polarity:\")\n",
    "\n",
    "top_20_reviews = reviews_nlp[['review', 'combined_review_polarity']].sort_values(\n",
    "    by='combined_review_polarity', ascending=False\n",
    ").head(20)\n",
    "\n",
    "top_20_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "print(\"Top 20 Positive Reviews by Combined Review Polarity:\")\n",
    "\n",
    "top_20_reviews_negative = reviews_nlp[['review', 'combined_review_polarity']].sort_values(\n",
    "    by='combined_review_polarity', ascending=True\n",
    ").head(20)\n",
    "\n",
    "top_20_reviews_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "print(\"Top 20 Positive Reviews by Combined Review Polarity:\")\n",
    "\n",
    "top_20_summary = reviews_nlp[['summary', 'combined_summary_polarity']].sort_values(\n",
    "    by='combined_summary_polarity', ascending=False\n",
    ").head(20)\n",
    "\n",
    "top_20_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if no_NLP\n",
    "\n",
    "print(\"Top 20 Positive Reviews by Combined Review Polarity:\")\n",
    "\n",
    "top_20_summary_negative = reviews_nlp[['summary', 'combined_summary_polarity']].sort_values(\n",
    "    by='combined_summary_polarity', ascending=True\n",
    ").head(20)\n",
    "\n",
    "top_20_summary_negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vec1 = reviews_nlp['combined_review_polarity'].fillna(0).values.reshape(1, -1)\n",
    "vec2 = reviews_nlp['combined_summary_polarity'].fillna(0).values.reshape(1, -1)\n",
    "\n",
    "cos_sim = cosine_similarity(vec1, vec2)[0][0]\n",
    "print(f\"Cosine Similarity: {cos_sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(np.abs(reviews_nlp['combined_review_polarity'] - reviews_nlp['combined_summary_polarity']))\n",
    "print(f\"Mean Absolute Difference: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absolute differences\n",
    "reviews_nlp['polarity_diff'] = (\n",
    "    abs(reviews_nlp['combined_review_polarity'] - reviews_nlp['combined_summary_polarity'])\n",
    ")\n",
    "\n",
    "# Filter out exact 0 differences\n",
    "nonzero_diff = reviews_nlp[reviews_nlp['polarity_diff'] != 0]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(nonzero_diff['polarity_diff'], bins=40, kde=True, color=\"#f38ba8\")\n",
    "plt.title('Distribution of Polarity Difference (Review - Summary)\\n(Excluding Zero Differences)')\n",
    "plt.xlabel('Polarity Difference')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by polarity_diff in descending order\n",
    "top_diff_reviews = reviews_nlp.sort_values(by='polarity_diff', ascending=False)\n",
    "\n",
    "# Display top 10 (or any N you want)\n",
    "top_diff_reviews[['review', 'summary', 'combined_review_polarity', 'combined_summary_polarity', 'polarity_diff']].head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = (reviews_nlp['polarity_diff'] > 0.5).sum()\n",
    "print(f\"Number of reviews where polarity difference exceeds 0.5: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_tag = reviews_nlp[reviews_nlp['polarity_diff'] > 0.5].copy()\n",
    "rows_to_tag = rows_to_tag.sort_values(by='polarity_diff', ascending=False)\n",
    "# rows_to_tag.to_csv('tagged_progress.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load manual tags\n",
    "tagged_df = pd.read_csv(\"tagged_progress.csv\")\n",
    "\n",
    "# Merge into main DataFrame\n",
    "reviews_nlp = reviews_nlp.merge(tagged_df, left_index=True, right_on='index', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'review': 0, 'between': 1, 'summary': 2}\n",
    "train_df = reviews_nlp[reviews_nlp['manual_sentiment_tag'].isin(label_map.keys())].copy()\n",
    "train_df['target'] = train_df['manual_sentiment_tag'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'textblob_review_polarity', 'vader_review_polarity', 'afinn_review_polarity',\n",
    "    'roberta_review_polarity', 'bert_review_polarity',\n",
    "    'textblob_summary_polarity', 'vader_summary_polarity', 'afinn_summary_polarity',\n",
    "    'roberta_summary_polarity', 'bert_summary_polarity'\n",
    "]\n",
    "\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['target']\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "X_all = reviews_nlp[features]\n",
    "reviews_nlp['rf_predicted_label'] = rf_model.predict(X_all)\n",
    "\n",
    "inv_label_map = {v: k for k, v in label_map.items()}\n",
    "reviews_nlp['rf_predicted_tag'] = reviews_nlp['rf_predicted_label'].map(inv_label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_nlp['best_rf_polarity'] = reviews_nlp.apply(get_best_rf_polarity, axis=1)\n",
    "reviews_cleaned['best_rf_polarity'] = reviews_nlp['best_rf_polarity'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
